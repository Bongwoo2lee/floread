{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **kobert 학습 가상환경에서 패키지 설치 & 깃 연동**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 4f21ba6] Add ve_kobert\n",
      " 3 files changed, 222 insertions(+), 156 deletions(-)\n",
      " create mode 100644 sentiment-analysis/ve_kobert.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git config --global core.autocrlf true\n",
    "!git add .\n",
    "!git commit -m \"Add ve_kobert\"\n",
    "# !git push origin feature_sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoBERT requirements(Hugging Face)\n",
    "\n",
    "**KoBERT/kobert_hf**  \n",
    "Python >= 3.6  \n",
    "PyTorch >= 1.8.1  \n",
    "transformers >= 4.8.2  \n",
    "sentencepiece >= 0.1.91  \n",
    "\n",
    "**KoBERT/requirements**  \n",
    "boto3 <=1.15.18  \n",
    "gluonnlp >= 0.6.0, <=0.10.0  \n",
    "mxnet >= 1.4.0, <=1.7.0.post2  \n",
    "onnxruntime == 1.8.0, <=1.8.0  \n",
    "sentencepiece >= 0.1.6, <=0.1.96  \n",
    "torch >= 1.7.0, <=1.10.1  \n",
    "transformers >= 4.8.1, <=4.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **가상/로컬 환경 설정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__코랩 패키지(코랩 상에 재설치 어려움)__\n",
    "```python\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"PyTorch version:\", torch.__version__, sys.version)\n",
    "print(\"CUDA version:\", torch.version.cuda, sys.version)\n",
    "```\n",
    "```bash\n",
    "Python version: 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
    "PyTorch version: 2.0.0+cu118 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
    "CUDA version: 11.8 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. GPU(Capability) & `CUDA` & `torch` & `mxnet` 호환성 확인(중요)**  \n",
    "\n",
    "1) gpu - cuda  \n",
    "https://www.wikiwand.com/en/CUDA\n",
    "\n",
    "2) Pytorch - CUDA  \n",
    "https://pytorch.org/get-started/previous-versions/  (v1.13.1 이하)  \n",
    "https://pytorch.org/get-started/locally/ (2.0.0)  \n",
    "\n",
    "3) mxnet - CUDA   \n",
    "https://mxnet.apache.org/versions/master/get_started?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.NVIDIA 드라이버, CUDA Toolkit, CuDNN, Visual Studio 설치**\n",
    "+ https://www.nvidia.com/Download/index.aspx?lang=kr\n",
    "+ https://developer.nvidia.com/cuda-toolkit-archive\n",
    "+ https://developer.nvidia.com/cudnn    (회원가입 필요)\n",
    "+ 깔려있지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 환경변수 설정**\n",
    "1) CuDNN파일 -> C:\\Program Files\\NVIDIA GPU Computing Toolkit (붙여넣기)\n",
    "2) 환경 변수 설정  \n",
    "    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin  \n",
    "    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\extras\\CUPTI\\libx64  \n",
    "    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\include\n",
    "\n",
    "+ CUDA 버전 확인 가능   \n",
    "`nvcc --version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019\n",
      "Cuda compilation tools, release 10.2, V10.2.89\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의. `nvidia-smi`가 출력하는 CUDA 버전이랑  CUDA Toolkit의 버전은 다르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  3 16:05:22 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 497.29       Driver Version: 497.29       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8    10W / 130W |    643MiB /  6144MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3256    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5784    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      5936    C+G   ...oft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A      9384    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9800    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10008    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     10796    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10820    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14888    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15120    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     15592    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A     17440    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     18360    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     20716    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     20876    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.패키지 설치**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.주피터실행 - 커널 선택하고 임포트 되는지 확인**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:39:05) [MSC v.1929 64 bit (AMD64)]\n",
      "\n",
      "PyTorch version: 1.8.1 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:39:05) [MSC v.1929 64 bit (AMD64)]\n",
      "\n",
      "CUDA version: 10.2 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:39:05) [MSC v.1929 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:\", sys.version,end = '\\n\\n')\n",
    "print(\"PyTorch version:\", torch.__version__, sys.version,end = '\\n\\n')\n",
    "print(\"CUDA version:\", torch.version.cuda, sys.version,end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~문제 많은 친구들~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "import gluonnlp \n",
    "import mxnet\n",
    "\n",
    "print(mxnet.__version__)\n",
    "print(gluonnlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 동작 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "print('cuda index:', torch.cuda.current_device())\n",
    "print('gpu 개수:', torch.cuda.device_count())\n",
    "print('graphic name:', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    a = torch.tensor([1.0, 2.0, 3.0], device=torch.device('cuda'))\n",
    "    b = torch.tensor([4.0, 5.0, 6.0], device=torch.device('cuda'))\n",
    "    c = a + b\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('kobert0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a424f62477de2ca37995ca837d4a36aa193720671fb7083e9553e863c62eb10b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
